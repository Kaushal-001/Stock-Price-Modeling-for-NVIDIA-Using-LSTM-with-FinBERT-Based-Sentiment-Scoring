# pipeline/pipeline_lstm.py

import os, sys
import mlflow
import mlflow.tensorflow
import joblib
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.callbacks import EarlyStopping

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

from src.data.load_data import load_data
from src.data.preprocess.preprocess_stock import preprocess_stock
from src.features.feature_engineering_stock import StockFeatureEngineer
from src.models.lstm_model import build_lstm_model


def main():

    print("\nğŸš€ Starting LSTM Training Pipeline...\n")

    DATA_PATH = os.path.join("news_data", "nvidia_stock.csv")

    # -------------------------------------------------------------
    # âœ… STEP 1 â€” Load Data
    # -------------------------------------------------------------
    print("ğŸ“¥ Loading CSV data...")
    df = load_data(DATA_PATH)
    print(f"âœ… Raw data loaded â†’ Shape: {df.shape}")
    print(df.head(), "\n")

    # -------------------------------------------------------------
    # âœ… STEP 2 â€” Preprocess
    # -------------------------------------------------------------
    print("ğŸ› ï¸ Preprocessing data...")
    df = preprocess_stock(df)
    print("âœ… Preprocessing complete!")
    print("ğŸ” Columns:", df.columns.tolist())
    print(df.head(), "\n")

    # -------------------------------------------------------------
    # âœ… STEP 3 â€” Extract Close Prices
    # -------------------------------------------------------------
    print("ğŸ“Š Extracting 'Close' column...")
    close_data = df[["Close"]].values
    print("âœ… Close data extracted â†’ Shape:", close_data.shape)
    print("   Min:", close_data.min(), "Max:", close_data.max(), "\n")

    # -------------------------------------------------------------
    # âœ… STEP 4 â€” Train/Test Split
    # -------------------------------------------------------------
    print("âœ‚ï¸ Splitting dataset (90% train, 10% test)...")
    split_ratio = 0.9
    train_len = int(len(close_data) * split_ratio)

    train_data = close_data[:train_len]
    test_data = close_data[train_len:]

    print(f"âœ… Train length: {len(train_data)}")
    print(f"âœ… Test length:  {len(test_data)}\n")

    # -------------------------------------------------------------
    # âœ… STEP 5 â€” Fit Scaler ONLY on Train
    # -------------------------------------------------------------
    SEQ_LEN = 60
    engineer = StockFeatureEngineer(seq_len=SEQ_LEN)

    print("ğŸ”§ Fitting StandardScaler on train data...")
    engineer.scaler.fit(train_data)
    print("âœ… Scaler fitted!")
    print("   Mean:", engineer.scaler.mean_)
    print("   Var :", engineer.scaler.var_, "\n")

    scaled_train = engineer.scaler.transform(train_data)
    scaled_test = engineer.scaler.transform(test_data)

    print("âœ… Scaled train shape:", scaled_train.shape)
    print("âœ… Scaled test  shape:", scaled_test.shape, "\n")

    # -------------------------------------------------------------
    # âœ… STEP 6 â€” Create Sequences
    # -------------------------------------------------------------
    print("ğŸ§© Creating sequences (X, y)...")

    def create_sequences(data, seq_len=60):
        X, y = [], []
        for i in range(seq_len, len(data)):
            X.append(data[i - seq_len:i])
            y.append(data[i])
        return np.array(X), np.array(y)

    X_train, y_train = create_sequences(scaled_train, SEQ_LEN)
    X_test, y_test = create_sequences(scaled_test, SEQ_LEN)

    print("âœ… X_train:", X_train.shape)
    print("âœ… y_train:", y_train.shape)
    print("âœ… X_test :", X_test.shape)
    print("âœ… y_test :", y_test.shape, "\n")

    # -------------------------------------------------------------
    # âœ… STEP 7 â€” Build Model
    # -------------------------------------------------------------
    print("ğŸ—ï¸ Building LSTM model...")
    model = build_lstm_model(
        input_shape=(SEQ_LEN, 1),
        lstm_units=128,
        dense_unit=128,
        dropout_rate=0.5350809294827892,
        optimizer="rmsprop"
    )
    print("âœ… Model built!\n")

    # -------------------------------------------------------------
    # âœ… STEP 8 â€” Setup MLflow
    # -------------------------------------------------------------
    print("ğŸ“¡ Setting MLflow tracking...")
    mlflow.set_tracking_uri("file:///Users/kaushaljha/Desktop/Stock_prediction_and_sentiment_analysis/mlruns")
    mlflow.set_experiment("nvidia_lstm_stock_prediction")
    print("âœ… MLflow Ready!\n")

    # -------------------------------------------------------------
    # âœ… STEP 9 â€” Train Model
    # -------------------------------------------------------------
    print("ğŸ‹ï¸ Starting training...")

    with mlflow.start_run(run_name="lstm_final_run"):

        mlflow.log_param("sequence_length", SEQ_LEN)
        mlflow.log_param("optimizer", "rmsprop")
        mlflow.log_param("lstm_units", 128)
        mlflow.log_param("dense_units", 128)

        early_stop = EarlyStopping(monitor="val_loss", patience=15, restore_best_weights=True)

        history = model.fit(
            X_train, y_train,
            validation_data=(X_test, y_test),
            epochs=14,
            batch_size=64,
            callbacks=[early_stop],
            verbose=1
        )

        print("\nâœ… Training complete!")

        # ---------------------------------------------------------
        # âœ… STEP 10 â€” Evaluate with All Metrics
        # ---------------------------------------------------------
        print("ğŸ“Š Computing evaluation metrics...")

        # Model's final test predictions
        y_pred_scaled = model.predict(X_test)

        # Undo standard scaling
        y_pred = engineer.scaler.inverse_transform(y_pred_scaled)
        y_true = engineer.scaler.inverse_transform(y_test)

        # Metrics
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        print(f"âœ… RMSE: {rmse:.4f}")
        print(f"âœ… MAE : {mae:.4f}")
        print(f"âœ… RÂ²  : {r2:.4f}\n")

        mlflow.log_metric("rmse", rmse)
        mlflow.log_metric("mae", mae)
        mlflow.log_metric("r2_score", r2)

        # ---------------------------------------------------------
        # âœ… STEP 11 â€” Save Model + Scaler
        # ---------------------------------------------------------
        print("ğŸ’¾ Saving model and scaler...")

        os.makedirs("models", exist_ok=True)
        MODEL_PATH = "models/lstm_stock_model.keras"
        SCALER_PATH = "models/standard_scaler.pkl"

        model.save(MODEL_PATH)
        joblib.dump(engineer.scaler, SCALER_PATH)

        mlflow.log_artifact(MODEL_PATH)
        mlflow.log_artifact(SCALER_PATH)

        print(f"âœ… Model saved â†’ {MODEL_PATH}")
        print(f"âœ… Scaler saved â†’ {SCALER_PATH}")
        print("âœ… MLflow Run Complete!\n")

    print("ğŸ‰ Pipeline Finished Successfully!")


if __name__ == "__main__":
    main()
